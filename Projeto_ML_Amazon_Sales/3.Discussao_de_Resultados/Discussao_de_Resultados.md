# ğŸ“ˆ DiscussÃ£o dos Resultados
ğŸ‡§ğŸ‡· PortuguÃªs

ğŸ“ VisÃ£o Geral  
A anÃ¡lise dos resultados evidencia que o modelo **Random Forest** apresentou o melhor desempenho geral entre os algoritmos avaliados, demonstrando maior capacidade de capturar padrÃµes nÃ£o lineares e interaÃ§Ãµes complexas entre as variÃ¡veis do conjunto de dados.

Os resultados obtidos sÃ£o consistentes com a literatura, que aponta modelos baseados em ensemble como mais robustos em cenÃ¡rios com mÃºltiplas variÃ¡veis explicativas e desbalanceamento de classes.

---

ğŸ” 1. ComparaÃ§Ã£o Detalhada entre os Modelos  
A comparaÃ§Ã£o entre os algoritmos testados mostrou que:

- **Random Forest** apresentou o melhor equilÃ­brio entre *precisÃ£o* e *recall*, reduzindo tanto falsos positivos quanto falsos negativos;
- O valor superior de **AUC** indica maior capacidade discriminativa entre as trÃªs classes de desempenho;
- Modelos como **RegressÃ£o LogÃ­stica** tiveram desempenho limitado devido Ã  suposiÃ§Ã£o de linearidade;
- **kNN** apresentou sensibilidade excessiva Ã  distribuiÃ§Ã£o dos dados;
- **SVM** teve dificuldades em separar adequadamente as classes minoritÃ¡rias.

Esses resultados reforÃ§am a adequaÃ§Ã£o do Random Forest para problemas de classificaÃ§Ã£o multiclasse em ambientes reais de negÃ³cio.

---

ğŸ“Š 2. AnÃ¡lise da Matriz de ConfusÃ£o  
A matriz de confusÃ£o do Random Forest revela padrÃµes importantes:

- A classe **Sucesso Moderado** foi identificada com alta taxa de acerto, indicando que o modelo consegue reconhecer padrÃµes tÃ­picos de produtos com desempenho intermediÃ¡rio;
- A confusÃ£o entre **Fracasso / Nicho** e **Sucesso Moderado** sugere uma fronteira menos clara entre essas categorias, o que Ã© esperado em cenÃ¡rios onde produtos possuem desempenho limÃ­trofe;
- A classe **Viral / Sucesso de Vendas** apresentou maior taxa de erro, principalmente devido ao baixo nÃºmero de exemplos disponÃ­veis para treinamento.

Esse comportamento indica que o modelo tende a privilegiar padrÃµes mais frequentes, caracterÃ­stica comum em bases desbalanceadas.

---

ğŸ“ 3. AvaliaÃ§Ã£o das MÃ©tricas de ClassificaÃ§Ã£o  
A anÃ¡lise das mÃ©tricas reforÃ§a os pontos observados anteriormente:

- A **acurÃ¡cia geral**, em torno de **0.77**, indica bom desempenho global;
- O **weighted average** das mÃ©tricas manteve-se prÃ³ximo de **0.75**, refletindo boa performance nas classes majoritÃ¡rias;
- O **macro average** apresentou valores inferiores, evidenciando que o desempenho nÃ£o Ã© homogÃªneo entre as classes.

Essa diferenÃ§a entre mÃ©tricas confirma o impacto direto do desbalanceamento da base sobre o modelo.

---

ğŸ§ª 4. AnÃ¡lise das PrevisÃµes na Base de Teste  
Ao aplicar o modelo Ã  base de teste, observou-se que:

- A maior parte dos produtos foi classificada como **Sucesso Moderado**, refletindo a distribuiÃ§Ã£o original das classes;
- Produtos classificados como **Fracasso / Nicho** apresentam menor potencial de vendas e podem demandar estratÃ©gias especÃ­ficas;
- Poucos produtos foram classificados como **Viral / Sucesso de Vendas**, o que Ã© coerente com a raridade desse comportamento no conjunto de dados.

Do ponto de vista de negÃ³cio, essas previsÃµes podem apoiar decisÃµes de priorizaÃ§Ã£o de investimentos em marketing e portfÃ³lio.

---

ğŸš§ 5. LimitaÃ§Ãµes do Estudo  
Apesar dos resultados satisfatÃ³rios, algumas limitaÃ§Ãµes devem ser destacadas:

- Forte **desbalanceamento entre as classes**, especialmente para a classe Viral;
- Quantidade reduzida de exemplos de alto sucesso;
- DependÃªncia exclusiva das variÃ¡veis disponÃ­veis na base atual;
- AusÃªncia de informaÃ§Ãµes temporais, que poderiam capturar tendÃªncias de vendas.

---

ğŸš€ 6. Trabalhos Futuros  
Como extensÃµes naturais do projeto, recomenda-se:

- Aplicar tÃ©cnicas de balanceamento, como **SMOTE** ou **undersampling**;
- Realizar ajuste fino de hiperparÃ¢metros do Random Forest;
- Avaliar outros mÃ©todos baseados em ensemble, como Gradient Boosting;
- Incorporar variÃ¡veis temporais e comportamentais;
- Explorar mÃ©tricas orientadas ao negÃ³cio, como custo de erro por classe.

---

## ğŸ‘¨â€ğŸ’» Autor

JoÃ£o Batista Nery  
[LinkedIn](https://www.linkedin.com/in/joaobatistanery)

---

ğŸ‡ºğŸ‡¸ English Version

# ğŸ›’ Machine Learning Project â€“ Product Success Prediction

ğŸ“ˆ Results Discussion

ğŸ“ Overview  
The results indicate that the **Random Forest** model achieved the best overall performance among the evaluated algorithms, showing strong capability to capture non-linear patterns and complex feature interactions.

These findings align with existing literature, which highlights ensemble-based models as robust solutions for multiclass and imbalanced datasets.

---

ğŸ” 1. Detailed Model Comparison  
The comparison shows that:

- **Random Forest** achieved the best balance between *precision* and *recall*;
- Higher **AUC** values indicate stronger discriminative power;
- **Logistic Regression** was limited by its linear assumptions;
- **kNN** was highly sensitive to data distribution;
- **SVM** struggled with minority class separation.

These results confirm Random Forest as a suitable model for real-world classification tasks.

---

ğŸ“Š 2. Confusion Matrix Analysis  
The confusion matrix reveals that:

- The **Moderate Success** class achieved high accuracy;
- Confusion between **Failure / Niche** and **Moderate Success** reflects unclear boundaries between borderline products;
- The **Viral / High Sales Success** class showed lower performance due to limited training samples.

This behavior highlights the influence of class imbalance.

---

ğŸ“ 3. Classification Metrics  
Metric analysis shows:

- Overall accuracy around **0.77**;
- Weighted averages close to **0.75**, driven by majority classes;
- Lower macro averages, indicating uneven performance across classes.

---

ğŸ§ª 4. Test Set Predictions  
When applied to the test set:

- Most products were classified as **Moderate Success**;
- Some were classified as **Failure / Niche**;
- Very few were classified as **Viral / High Sales Success**, consistent with training distribution.

From a business perspective, these predictions can support strategic decision-making.

---

ğŸš§ 5. Study Limitations  
Key limitations include:

- Significant class imbalance;
- Few viral examples;
- Limited feature set;
- Lack of temporal data.

---

ğŸš€ 6. Future Work  
Future improvements may include:

- Applying class balancing techniques;
- Hyperparameter tuning;
- Testing additional ensemble algorithms;
- Adding temporal and behavioral features;
- Evaluating business-oriented metrics.

## ğŸ‘¨â€ğŸ’» Author

JoÃ£o Batista Nery  
[LinkedIn](https://www.linkedin.com/in/joaobatistanery)

---
